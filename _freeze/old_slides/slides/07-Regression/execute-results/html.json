{
  "hash": "316ac58bf099cd0386caebf095612253",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression\"\nsubtitle: 'Estimating models and predicting values with R'\ncompany: \"University of Potsdam\"\nauthor: \"Jürgen Wilbert\"\ndate: \"Version: 15 May 2025\"\n---\n\n\n\n\n\n## Goals {.emphasized data-background=img/DEFOCUSED.png data-background-size=cover .flexbox .vcenter}\n\n- An introduction to regression analyses\n- An introduction to fitting regression models in R\n\n\n\n\n## Regression {.columns-2 .smaller}\n\n$y_i = \\beta_0 + \\beta_1X_i + e_i$\n\n\n$y$ = Criteria variable  \n$i$ = Subject number (measurement number)  \n$\\beta_0$ = Intercept of $y$  \n$\\beta_1$ = Weight of predictor $X$  \n$X$ = Predictor variable  \n$e$ = Error term  \n\n<p class=\"forceBreak\"></p>\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-Regression_files/figure-revealjs/unnamed-chunk-1-1.png){width=480}\n:::\n:::\n\n\n\n\n\n## `lm()` function\n\n- The `lm()` function fits a regression model.\n- `lm(formula, data)`\n- ***Formulas*** are a basic data type that is applied in many R functions.\n- Basic structur:  ***dependent variable ~ explanatory variables***  (e.g. ***y ~ x1 + x2***)\n- `data` takes a dataframe\n\n`lm(dist ~ speed, data = cars)`\n\n## Example\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-Regression_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(dist ~ speed, data = cars)\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nCoefficients:\n(Intercept)        speed  \n    -17.579        3.932  \n```\n\n\n:::\n:::\n\n\n\n$dist_i = -17.579 + 3.932 * speed_i$\n\n## Summary {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,\tAdjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n```\n\n\n:::\n:::\n\n\n\nModelfit:  \n$F(1, 48) = 89.57; p < .001 ; R² = .65$\n\n## Task\n\n- Take the `mtcars` dataset\n- Calculate the correlation of mileage `mpg` and car weight `wt`\n- Plot a scatterplot with mileage on x and weight on y\n- Add a regression line with (`geom_smooth(method = \"lm\")`)\n- Regress mileage `mpg` on car weight `wt` (that is, predic mileage by means of weight)\n\n\n\n## Task {.columns-2 .smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(mtcars$mpg, mtcars$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8676594\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(mtcars, aes(x = mpg, y = wt)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](07-Regression_files/figure-revealjs/unnamed-chunk-5-1.png){width=384}\n:::\n\n```{.r .cell-code}\nfit <- lm(mpg ~ wt, data = mtcars)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n```\n\n\n:::\n:::\n\n\n\n## Multiple predictors\n\n- A `formula` can take multiple predictors: `y ~ x1 + x2`\n- An Interaction describes a relationi between two (or more) predictors where influce of one predictor changes with the value of the other predictor (e.g. weight and smoking  influence blood preassure. And the influence of smoking is even highe for those who are overweight)\n- An interaction is modelled with a `:` sign: y ~ x1 + x2 + x1:x2\n\n## Task\n\n- Take the `mtcars` dataset\n- Predict mileage `mpg` by weight `wt` and number of cylinders `cyl`\n- Take the interaction into account\n- Discuss with your seatmate how to interpret the estimates\n\n\n## {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(mpg ~ wt + cyl + wt:cyl, data = mtcars)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + cyl + wt:cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2288 -1.3495 -0.5042  1.4647  5.2344 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  54.3068     6.1275   8.863 1.29e-09 ***\nwt           -8.6556     2.3201  -3.731 0.000861 ***\ncyl          -3.8032     1.0050  -3.784 0.000747 ***\nwt:cyl        0.8084     0.3273   2.470 0.019882 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.368 on 28 degrees of freedom\nMultiple R-squared:  0.8606,\tAdjusted R-squared:  0.8457 \nF-statistic: 57.62 on 3 and 28 DF,  p-value: 4.231e-12\n```\n\n\n:::\n:::\n\n\n\n## Categorical data\n\n- Predictors can be categorical variables\n- They have to be `factors`for `formulas` to recognice them as `categorical`\n- Remember: you can create a factor with the `factor()` function\n\n## Task\n\n- Take the `mtcars` dataset\n- Predict `mpg` by `wt` and the transmission type `am` and their interaction\n- By deafult `am` is not a factor. Please create a factor for `am` first\n- Discuss with you seatmate how to interpret the estimates\n\n##\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars$am_factor <- factor(mtcars$am, labels = c(\"Automatic\", \"Manual\"))\nfit <- lm(mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6004 -1.5446 -0.5325  0.9012  6.0909 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         31.4161     3.0201  10.402 4.00e-11 ***\nwt                  -3.7859     0.7856  -4.819 4.55e-05 ***\nam_factorManual     14.8784     4.2640   3.489  0.00162 ** \nwt:am_factorManual  -5.2984     1.4447  -3.667  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.591 on 28 degrees of freedom\nMultiple R-squared:  0.833,\tAdjusted R-squared:  0.8151 \nF-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11\n```\n\n\n:::\n:::\n\n\n\n## Changing the contrast\n\n\n- Contrasts describe how to compare the influnce of two (or more) factor levels.\n- Two common ways are:\n    - Treatment: One factor level is the baseline\n    - Helmert: The average of the two factor levels are the baseline\n- The `constrasts()` function gets and sets contrasts for factors\n- Treatment contrasts for two factor levels:  \n    `contrasts(mtcars$am_factor) <- contr.treatment(2)`\n- Helmert contrasts for two factor levels:  \n    `contrasts(mtcars$am_factor) <- contr.helmert(2)`\n\n## Task {.smaller}\n    \n- Take the `mtcars` dataset\n- Predict `mpg` by `wt` and the transmission type `am` and their interaction\n- By deafult `am` is not a factor. Please create a factor for `am` first\n- Set the contrasts of the factor to *Helmert* and calculate the model.\n- Set the contrasts of the factor to *Treatment* and calculate the model\n- Compare the results of the two models and discuss them with you seatmate\n\n## \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars$am_factor <- factor(mtcars$am, labels = c(\"Automatic\", \"Manual\"))\ncontrasts(mtcars$am_factor) <- contr.helmert(2)\nfit1 <- lm(mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6004 -1.5446 -0.5325  0.9012  6.0909 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    38.8553     2.1320  18.225  < 2e-16 ***\nwt             -6.4351     0.7223  -8.909 1.16e-09 ***\nam_factor1      7.4392     2.1320   3.489  0.00162 ** \nwt:am_factor1  -2.6492     0.7223  -3.667  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.591 on 28 degrees of freedom\nMultiple R-squared:  0.833,\tAdjusted R-squared:  0.8151 \nF-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11\n```\n\n\n:::\n\n```{.r .cell-code}\ncontrasts(mtcars$am_factor) <- contr.treatment(2)\nfit2 <- lm(mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + am_factor + wt:am_factor, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6004 -1.5446 -0.5325  0.9012  6.0909 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    31.4161     3.0201  10.402 4.00e-11 ***\nwt             -3.7859     0.7856  -4.819 4.55e-05 ***\nam_factor2     14.8784     4.2640   3.489  0.00162 ** \nwt:am_factor2  -5.2984     1.4447  -3.667  0.00102 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.591 on 28 degrees of freedom\nMultiple R-squared:  0.833,\tAdjusted R-squared:  0.8151 \nF-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11\n```\n\n\n:::\n:::\n\n\n\n\n## Multilevel regression formula {.smaller}\n\n$y_{ij} = \\beta_{0j} + \\beta_{1j} X_{ij} + e_{ij}$\n\nLevel 2:  \n$\\beta_{0j} = \\gamma_{01}W_j + \\upsilon_{0j}$  \n$\\beta_{1j} = \\gamma_{10} + \\upsilon_{1j}$  \n\n$y$ = Criteria variable  \n$i$ = Subject number (measurement number)  \n$\\beta_0$ = Intercept of $y$  \n$\\beta_1$ = Weight of predictor $X$  \n$X$ = Predictor variable  \n$e$ = Error term  \n$j$ = Level 2 group number  \n$\\gamma_{00}$ = Intercept  \n$W$ = Level 2 predictor (grouping variable)  \n$\\gamma_{01}$ = Weight for $W$  \n$\\upsilon_{0j}$ = Error term for intercept\n$\\gamma_{10}$ = Weight of the predictor     \n$\\upsilon_{0j}$ = Error term for slope  \n\n",
    "supporting": [
      "07-Regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}